{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91cfa312",
   "metadata": {},
   "source": [
    "# Uniformar los datos satelitales de NASA - diarios por estaci칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0f0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4499bd3",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5d9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Definir perido de los datos'''\n",
    "fecha_ini = '1981-01-01'\n",
    "fecha_fin = '2020-12-31'\n",
    "\n",
    "'''devolver la fecha en base al a침o y el numero de dia'''\n",
    "def aniodia(anio, dia=1):\n",
    "    fecha = pd.to_datetime(dia-1, unit='D', origin=str(anio))\n",
    "    return fecha.date()\n",
    "\n",
    "'''devolver el rango de fecha en base al a침o, dia inicial y periodo'''\n",
    "def rango_fecha1(anio, dia, periodo):\n",
    "    rango = pd.date_range(start = aniodia(anio, dia), freq = 'D', periods = periodo)\n",
    "    return rango\n",
    "\n",
    "'''leer los archivos en un carpeta dada SI son archivos CSV y si su nombre comienza con NASA'''\n",
    "def leer_dir(path):\n",
    "    with os.scandir(path) as ficheros:\n",
    "        ficheros = [fichero.name for fichero in ficheros if fichero.is_file() \\\n",
    "                    and fichero.name.endswith('.csv') and fichero.name.startswith('nasa')]\n",
    "    ficheros.sort()\n",
    "    return ficheros\n",
    "\n",
    "'''crear un DF con una sola columna en base a otro DF y una columna del mismo'''\n",
    "def creardf(data, col):\n",
    "    dat = pd.DataFrame()\n",
    "    dat[col] = data[col]\n",
    "    return dat\n",
    "\n",
    "'''guardar un DF en base a un nombre y un directorio'''\n",
    "def guardar(data, nom, path='../datos/1.0.variables/'):\n",
    "    pth = path + nom\n",
    "    data.to_csv(pth, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eab4d2",
   "metadata": {},
   "source": [
    "### Generar archivos con datos uniformados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bec80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_f4 = '../datos/1.3.formato5_nasa/'\n",
    "archivos = leer_dir(dir_f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b97c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for p in archivos:\n",
    "    ruta = dir_f4 + p\n",
    "    data = pd.read_csv(ruta, skiprows=13)\n",
    "    \n",
    "    '''leer anio y dia de inicio'''\n",
    "    anio = data.iloc[0,0]\n",
    "    dia = data.iloc[0,1]\n",
    "    dias = data.shape[0]\n",
    "    \n",
    "    '''adicionar la columna fecha'''\n",
    "    data['fecha'] = rango_fecha1(anio, dia, dias)\n",
    "    \n",
    "    '''cambiar de nombre las columnas'''\n",
    "    data = data.rename(columns={\"fecha\": \"fecha\", \"PRECTOTCORR\": \"pp\", \"T2M_MAX\":\\\n",
    "                                \"tmax\", \"T2M_MIN\": \"tmin\", \"T2M\": \"tmed\", \"RH2M\": \"hmed\"})\n",
    "\n",
    "    '''reordenar las columnas y eliminar columnas YEAR y DOY'''\n",
    "    data = data.reindex(['fecha','pp','tmax','tmin','tmed','hmed'], axis=1)    \n",
    "    \n",
    "    '''periodo de datos'''\n",
    "    data = data[(data['fecha'] >= fecha_ini) & (data['fecha'] <= fecha_fin)]\n",
    "    \n",
    "    '''guardar archivo'''\n",
    "    dir_guardar = '../datos/1.0.formato_csv_corregido/' + p\n",
    "    data.to_csv(dir_guardar, index = False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af542f26",
   "metadata": {},
   "source": [
    "### Generar archivos para cada variable meteorol칩gica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6412b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''llamar a la funcion LEER_DIR() para recuperar archivos de un directorio'''\n",
    "lista_arch = leer_dir('../datos/1.0.formato_csv_corregido/')\n",
    "\n",
    "'''leer un DF en forma temporal'''\n",
    "pin = '../datos/1.0.formato_csv_corregido/' + lista_arch[0]\n",
    "temp = pd.read_csv(pin)\n",
    "\n",
    "'''crear DF para cada variable, tomando como base el DF TEMP'''\n",
    "dfpp = creardf(temp,['fecha'])\n",
    "dftmx = creardf(temp,['fecha'])\n",
    "dftmn = creardf(temp,['fecha'])\n",
    "dftmd = creardf(temp,['fecha'])\n",
    "dfhmd = creardf(temp,['fecha'])\n",
    "\n",
    "'''crear una lista con los nombres de las columnas'''\n",
    "nom_col = ['fecha']\n",
    "\n",
    "for p in lista_arch:\n",
    "    pin = '../datos/1.0.formato_csv_corregido/' + p\n",
    "    file = pd.read_csv(pin)\n",
    "    dfpp = pd.concat([dfpp, file['pp']], axis=1)\n",
    "    dftmx = pd.concat([dftmx, file['tmax']], axis=1)\n",
    "    dftmn = pd.concat([dftmn, file['tmin']], axis=1)\n",
    "    dftmd = pd.concat([dftmd, file['tmed']], axis=1)\n",
    "    dfhmd = pd.concat([dfhmd, file['hmed']], axis=1)\n",
    "    \n",
    "    cad = p.split('_')\n",
    "    nom_col.append(str(cad[1]))\n",
    "    \n",
    "dfpp.columns = nom_col\n",
    "dftmx.columns = nom_col\n",
    "dftmn.columns = nom_col\n",
    "dftmd.columns = nom_col\n",
    "dfhmd.columns = nom_col\n",
    "\n",
    "guardar(dfpp, 'nasa_diario_pp.csv')\n",
    "guardar(dftmx, 'nasa_diario_tmax.csv')\n",
    "guardar(dftmn, 'nasa_diario_tmin.csv')\n",
    "guardar(dftmd, 'nasa_diario_tmed.csv')\n",
    "guardar(dfhmd, 'nasa_diario_hmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b38771c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        fecha    100    101    102    105    106    107    108    111    112  \\\n",
      "0  1981-01-02   0.77   0.35   0.41   0.77   0.58   0.36   0.55   0.22   0.58   \n",
      "1  1981-01-03   3.17   1.88   2.50   3.17   2.90   2.53   2.67   1.32   2.90   \n",
      "2  1981-01-04  17.93  16.86  19.41  17.93  16.50  18.94  15.23  10.95  16.50   \n",
      "3  1981-01-05  11.58   8.82  10.20  11.58   7.53   9.89   6.97   7.15   7.53   \n",
      "4  1981-01-06   1.61   3.41   1.71   1.61   2.61   1.77   2.48   1.60   2.61   \n",
      "\n",
      "   ...    118    119    120    121    200    201   202    203   204    205  \n",
      "0  ...   0.23   0.35   0.30   0.58   3.05   3.31  0.92   1.72  1.61   1.69  \n",
      "1  ...   2.02   1.88   2.01   2.90   7.27   8.05  2.17   4.86  3.82   4.51  \n",
      "2  ...  15.43  16.86  19.44  16.50  10.77  11.30  3.28  12.88  4.54  17.88  \n",
      "3  ...   7.43   8.82   7.54   7.53   4.29   4.13  1.34   5.48  2.01   8.67  \n",
      "4  ...   1.18   3.41   4.15   2.61  11.09  12.26  3.38   6.59  5.48   4.35  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "'''Dataframe precipitacion con datos de NASA'''\n",
    "print(dfpp.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
