{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f97e9e",
   "metadata": {},
   "source": [
    "# Convertir archivos excel de SENAMHI a archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0eaa09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'instalar openpyxl para abrir varias hojas de un libro de excel'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''instalar openpyxl para abrir varias hojas de un libro de excel'''\n",
    "# %pip install openpyxl\n",
    "# %pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104fd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from calendar import monthrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25d62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18ec02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876af200",
   "metadata": {},
   "source": [
    "# Convertir de formato obtenido a fomato CSV\n",
    "\n",
    "Leer los datos del archivo CSV 'estaciones_senamhi'.\n",
    "Las columnas que nos interesan:\n",
    " - path_format contiene las rutas relativas de los archivos,\n",
    " - path_csv contiene las rutas relativas para guardar los arvhivos resultantes\n",
    " - f contiene el tipo de formato que tiene cada archivo <1 , 2 , 3>\n",
    "\n",
    "## Formato 1, 2, 3 a formato CSV\n",
    "Definimos los metodos para las diferentes operaciones y cálculos\n",
    "Para un dataframe de la forma\n",
    "\n",
    "| anio = 2003 | | | | | | | | | | | | | |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---|\n",
    "| DIA | ENE | FEB | MAR | ABR | MAY | JUN | JUL | AGO | SEP | OCT | NOV | DIC | TOTAL |\n",
    "|1|  1  |  2  |  3  |  4  |     |  2  |  3  |  3  |  5  |  1  |     |     |  x|\n",
    "|2|  0  |  0  |  0  |  0  |  0  |  9  |  8  |  5  |  3  |     |     |     |  y|\n",
    "|...| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ...|\n",
    "|30  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  z|\n",
    "|31  |  5  |  1  |     |     |  5  |  1  |     |     |  5  |  1  |     |     |  w|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be9d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''devuelve la cadena \"2003\" convertida en INT, enviadole un DF y el Indice donde se encuentra'''\n",
    "def es_anio(data, indice):\n",
    "    '''recuperar el valor del indice y columna'''\n",
    "    cadena = data.iloc[indice,0]\n",
    "    '''separa la cadena en base al caracter \" \" (espacio)'''\n",
    "    an = cadena.split(' ')\n",
    "    '''devulve el anio, previamente lo convierte en Entero'''\n",
    "    return int(an[1])\n",
    "\n",
    "'''devuelve los datos diarios de cada mes en el anio especificado, traspuestos al formato de entrada'''\n",
    "def anio_datos (data, indice):\n",
    "    '''declarar fila(indice) de inicio y fin de los datos del anio'''\n",
    "    filaini = indice + 2\n",
    "    filafin = indice + 33\n",
    "    '''extraer los datos contenidos entre los limites'''\n",
    "    df1 = data.iloc[filaini:filafin , 1:13]\n",
    "    '''resetear el indice'''\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    '''transponer los datos obtenidos y resetear el indice'''\n",
    "    df2=df1.T\n",
    "    df2.reset_index(drop=True, inplace = True)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89824e0",
   "metadata": {},
   "source": [
    "#### La siguiente función devuelve un dataframe de la forma\n",
    "\n",
    "| anio | mes |  1  |  2  | ... | 30 | 31|\n",
    "| --- | --- | --- | --- | --- | --- | ---|\n",
    "| yyyy | m01 |  0  |     | ... |  0 |  1|\n",
    "| yyyy | m02 |  1  |  0  | ... |    |  2|\n",
    "| .... | ... | ... | ... | ... | .. | ..|\n",
    "| yyyy | m11 |  0  |  0  | ... |  0 |  0|\n",
    "| yyyy | m12 |     |  0  | ... |    |  2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8458a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anio_comple(data, indice):\n",
    "    '''crear un df vacio con las columnas anio y mes'''\n",
    "    am = pd.DataFrame(columns = ['anio', 'mes'])\n",
    "    '''rellenar las columnas mes y anio'''\n",
    "    am ['mes'] = np.arange(1, 13)\n",
    "    am ['anio'] = es_anio(data, indice)\n",
    "    '''recuperar el df transpuesto'''\n",
    "    dfa = anio_datos(data, indice)\n",
    "    df = pd.concat([am, dfa], axis = 1)\n",
    "    return df\n",
    "\n",
    "'''recorrer todo el libro para recuperar todos los anios'''\n",
    "def medida(data):\n",
    "    i = 0\n",
    "    '''cantidad total de filas en el df'''\n",
    "    n = data.shape [0]\n",
    "    dfall = pd.DataFrame()\n",
    "    while i<n:\n",
    "        dfanio = anio_comple(data, i)\n",
    "        dfall = pd.concat([dfall, dfanio], axis = 0)\n",
    "        dfall.reset_index(drop = True, inplace = True)\n",
    "        i += 39\n",
    "    return dfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "685aadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''funcion que devuelve la fecha de inicio y finalizacion de los datos disponibles de un df'''\n",
    "def cont_val(df1):\n",
    "    if min(df1.shape)!=0:\n",
    "        amin = df1['anio'].min()\n",
    "        amax = df1['anio'].max()\n",
    "        mmin = df1[df1['anio']==amin]['mes'].min()\n",
    "        mmax = df1[df1['anio']==amax]['mes'].max()\n",
    "        dmax = max(monthrange(amax, mmax))\n",
    "        fecha1=datetime.date(amin, mmin, 1)\n",
    "        fecha2=datetime.date(amax, mmax, dmax)\n",
    "    else:\n",
    "        fecha1 = pd.NaT\n",
    "        fecha2 = pd.NaT\n",
    "    return [fecha1, fecha2]\n",
    "\n",
    "'''funcion que genera el df de cada medicion'''\n",
    "def generar_df(d1, d2, df_medicion):\n",
    "    var_fijas = [\"anio\",\"mes\"]\n",
    "    var_melt = df_medicion.columns.difference(pd.Index(var_fijas))\n",
    "    df_dia= pd.melt(df_medicion,id_vars=var_fijas,value_vars=var_melt, var_name=\"dia\",value_name=\"valor\").sort_values(by=[\"anio\",\"mes\",\"dia\"]).reset_index(drop=True)\n",
    "    df_dia['dia']=df_dia['dia'].astype(int)\n",
    "    df_datos = df_dia.sort_values(by=[\"anio\",\"mes\",\"dia\"]).reset_index(drop=True)\n",
    "    \n",
    "    '''crear un dataframe vacio con las columnas anio, mes, dia, value'''\n",
    "    df1 = pd.DataFrame(columns=['anio','mes','dia','valor'])\n",
    "\n",
    "    '''crear una columna con las fechas dentro el rango'''\n",
    "    df1['fecha']=pd.date_range(start=d1,end=d2)\n",
    "\n",
    "    '''asignar las columnas de anio, mes, dia con los valores del rango'''\n",
    "    df1['anio'] = df1['fecha'].dt.year\n",
    "    df1['mes'] = df1['fecha'].dt.month\n",
    "    df1['dia'] = df1['fecha'].dt.day\n",
    "\n",
    "    '''eliminar la columna fecha'''\n",
    "    df1.drop(['fecha'], axis=1, inplace=True)\n",
    "    \n",
    "    '''crear listas para cada ciclo'''\n",
    "    rango_anio = list(df1['anio'].unique())\n",
    "    for x in rango_anio:\n",
    "        rango_mes = list(df1[df1['anio']==x]['mes'].unique())\n",
    "        for y in rango_mes:\n",
    "            rango_dia = list(df1[(df1['anio']==x) & (df1['mes']==y)]['dia'].unique())\n",
    "            for z in rango_dia:\n",
    "                '''asignar el subdataframe con la condicion'''\n",
    "                aux = pd.DataFrame()\n",
    "                aux = df_datos[(df_datos['anio']==x) & (df_datos['mes']==y) & (df_datos['dia']==z)]\n",
    "                '''evaluar el tamaño del subdataframe'''\n",
    "                if min(aux.shape)!=0:\n",
    "                    '''reiniciar el indice del subdataframe'''\n",
    "                    aux.reset_index(drop=True, inplace=True)\n",
    "                    '''obtener el indice de la fila con la fecha requerida y asignar el valor correspondiente'''\n",
    "                    indice = df1.index[(df1['anio']==x) & (df1['mes']==y) & (df1['dia']==z)]\n",
    "                    df1.loc[indice, 'valor'] = aux.loc[0, 'valor']\n",
    "    return df1\n",
    "\n",
    "\n",
    "'''leer datos desde un archivo con formato 1'''\n",
    "def leer1(path_f01):\n",
    "    '''leer los datos desde un xlsx, las primeras 7 hojas'''\n",
    "    cab_1=['anio', 'mes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "    hoj_1=['CODP1', 'CODP2', 'CODP3', 'CODP4', 'CODP5']\n",
    "#     hoj_1=['CODP1', 'CODP2', 'CODP3', 'CODP4', 'CODP5', 'CODP6', 'CODP7']\n",
    "    libro = pd.read_excel(path_f01, sheet_name=hoj_1, skiprows=5, names=cab_1)\n",
    "    return libro\n",
    "\n",
    "'''retorna el archivo csv, enviando el libro como datos'''\n",
    "def asignar1(data):\n",
    "    '''asignar el contenido del DICTIONARY a dataframes'''\n",
    "    dfpp=pd.DataFrame(data['CODP1'])\n",
    "    dftmax=pd.DataFrame(data['CODP3'])\n",
    "    dftmin=pd.DataFrame(data['CODP2'])\n",
    "    dftmed=pd.DataFrame(data['CODP4'])\n",
    "    dfhmed=pd.DataFrame(data['CODP5'])\n",
    "    \n",
    "    \n",
    "    '''llamar a la funcion cont_val para calcular el rango de fechas'''\n",
    "    rpp = cont_val(dfpp)\n",
    "    rtmax = cont_val(dftmax)\n",
    "    rtmin = cont_val(dftmin)\n",
    "    rtmed = cont_val(dftmed)\n",
    "    rhmed = cont_val(dfhmed)\n",
    "    col=['fec_ini', 'fec_fin']\n",
    "    indic = ['pp', 'tmax', 'tmin', 'tmed', 'hmed']\n",
    "    df_fecha = pd.DataFrame([rpp, rtmax, rtmin, rtmed, rhmed], columns=col, index = indic)\n",
    "    fecha_min = min(df_fecha['fec_ini'])\n",
    "    fecha_max = max(df_fecha['fec_fin'])\n",
    "\n",
    "    '''llamar a la funcion generar_df para generar los df con la misma fecha de inicio y finalizacion'''\n",
    "    rpp = generar_df(fecha_min, fecha_max, dfpp)\n",
    "    rtmax = generar_df(fecha_min, fecha_max, dftmax)\n",
    "    rtmin = generar_df(fecha_min, fecha_max, dftmin)\n",
    "    rtmed = generar_df(fecha_min, fecha_max, dftmed)\n",
    "    rhmed = generar_df(fecha_min, fecha_max, dfhmed)\n",
    "    \n",
    "    '''concatenar los resultados parciales'''\n",
    "    df_estacion1 = pd.concat([rpp['anio'], rpp['mes'], rpp['dia'], rpp['valor'], rtmax['valor'], rtmin['valor'], rtmed['valor'], rhmed['valor']], axis=1)\n",
    "\n",
    "    '''cambiar los nombres de las columnas'''\n",
    "    df_estacion1.columns = ['anio','mes','dia','pp','tmax','tmin','tmed','hmed']    \n",
    "    \n",
    "    return df_estacion1\n",
    "\n",
    "\n",
    "'''metodo para cambiar de nombre las columnas(nomcols) de un df(data) que no tiene datos'''\n",
    "def col_nom(data, nomcols):\n",
    "    '''si el df esta vacio'''\n",
    "    if data.shape[0] != 0:\n",
    "        '''retorna el df actualizado'''\n",
    "        data.columns = nomcols\n",
    "        return data\n",
    "    else:\n",
    "        '''retorna un df vacio con columnas'''\n",
    "        data0 = pd.DataFrame(columns = nomcols)\n",
    "        return data0\n",
    "\n",
    "\n",
    "'''leer datos de un archivo con formato 2'''\n",
    "def leer2(path_f02):\n",
    "    '''leer los datos desde un xlsx, las primeras 7 hojas'''\n",
    "    hoj_2 = ['Hoja1', 'Hoja2', 'Hoja3', 'Hoja4', 'Hoja5']\n",
    "    try:\n",
    "        libro = pd.read_excel(path_f02, header = None, sheet_name = hoj_2, skiprows = 4)\n",
    "    except ValueError:\n",
    "        libro = pd.read_excel(path_f02, header = None, sheet_name = 'Hoja1', skiprows = 4)\n",
    "        \n",
    "    '''asignar el contenido del DICTIONARY a dataframes'''\n",
    "    if isinstance (libro, dict):\n",
    "        dpp=pd.DataFrame(libro['Hoja1'])\n",
    "        dtmax=pd.DataFrame(libro['Hoja2'])\n",
    "        dtmin=pd.DataFrame(libro['Hoja3'])\n",
    "        dtmed=pd.DataFrame(libro['Hoja4'])\n",
    "        dhmed=pd.DataFrame(libro['Hoja5'])\n",
    "\n",
    "    '''llamar a la funcion para generar el formato horizontal'''\n",
    "    if isinstance (libro, dict):\n",
    "        dfpp = medida(dpp)\n",
    "        dftmax = medida(dtmax)\n",
    "        dftmin = medida(dtmin)\n",
    "        dftmed = medida(dtmed)\n",
    "        dfhmed = medida(dhmed)\n",
    "    else:\n",
    "        dfpp = medida(libro)\n",
    "\n",
    "    '''cambiar las columnas de los df'''\n",
    "    cols = ['anio', 'mes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "\n",
    "    if isinstance (libro, dict):\n",
    "        dfpp = col_nom(dfpp, cols)\n",
    "        dftmax = col_nom(dftmax, cols)\n",
    "        dftmin = col_nom(dftmin, cols)\n",
    "        dftmed = col_nom(dftmed, cols)\n",
    "        dfhmed = col_nom(dfhmed, cols)\n",
    "    else:\n",
    "        dfvacio = pd.DataFrame()\n",
    "        dfpp = col_nom(dfpp, cols)\n",
    "        dftmax = col_nom(dfvacio, cols)\n",
    "        dftmin = col_nom(dfvacio, cols)\n",
    "        dftmed = col_nom(dfvacio, cols)\n",
    "        dfhmed = col_nom(dfvacio, cols)\n",
    "    \n",
    "    '''llamar a la funcion cont_val para calcular el rango de fechas'''\n",
    "    fecpp = cont_val(dfpp)\n",
    "    fectmax = cont_val(dftmax)\n",
    "    fectmin = cont_val(dftmin)\n",
    "    fectmed = cont_val(dftmed)\n",
    "    fechmed = cont_val(dfhmed)\n",
    "    col=['fec_ini', 'fec_fin']\n",
    "    indic = ['pp', 'tmax', 'tmin', 'tmed', 'hmed']\n",
    "    df_fecha = pd.DataFrame([fecpp, fectmax, fectmin, fectmed, fechmed], columns=col, index = indic)\n",
    "    fecha_min = min(df_fecha['fec_ini'])\n",
    "    fecha_max = max(df_fecha['fec_fin'])\n",
    "\n",
    "    '''llamar a la funcion generar_df para generar los df con la misma fecha de inicio y finalizacion'''\n",
    "    rpp = generar_df(fecha_min, fecha_max, dfpp)\n",
    "    rtmax = generar_df(fecha_min, fecha_max, dftmax)\n",
    "    rtmin = generar_df(fecha_min, fecha_max, dftmin)\n",
    "    rtmed = generar_df(fecha_min, fecha_max, dftmed)\n",
    "    rhmed = generar_df(fecha_min, fecha_max, dfhmed)\n",
    "\n",
    "    '''concatenar los resultados parciales'''\n",
    "    df_estacion2 = pd.concat([rpp['anio'], rpp['mes'], rpp['dia'], rpp['valor'], rtmax['valor'], rtmin['valor'], rtmed['valor'], rhmed['valor']], axis=1)\n",
    "    '''cambiar los nombres de las columnas'''\n",
    "    df_estacion2.columns = ['anio','mes','dia','pp','tmax','tmin','tmed','hmed']\n",
    "    \n",
    "    return df_estacion2\n",
    "\n",
    "'''leer datos de un archivo con formato 3'''\n",
    "def leer3(path_f03):\n",
    "    df03 = pd.read_csv(path_f03)\n",
    "    return df03\n",
    "\n",
    "def grabar(data, path_f):\n",
    "    ''''grabar el dataframe resultante en un archivo csv'''\n",
    "    data.to_csv(path_f, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d5645",
   "metadata": {},
   "source": [
    "### Leer archivo estaciones_senamhi.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a72eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = '../datos/1.0.Estaciones/estaciones_senamhi.csv'\n",
    "dflista = pd.read_csv(path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2efc4",
   "metadata": {},
   "source": [
    "### Realizar operaciones para generar archivos CSV de cada estación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e73c3a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_f = dflista.shape[0]\n",
    "dflista['archivo_csv']=''\n",
    "for i in range(0, total_f):\n",
    "    '''ruta del archivo'''\n",
    "    nom_arch0 = dflista['nom_archivo'][i]\n",
    "    cond = dflista['formato'][i]\n",
    "    ruta_archivo = '../datos/1.0.formato'+str(cond)+'/'+nom_arch0\n",
    "    if (cond == 1):\n",
    "        '''para formato 1'''\n",
    "        dfarchivo = leer1(ruta_archivo)\n",
    "        df0_res = asignar1(dfarchivo)\n",
    "    else:\n",
    "        if (cond == 2):\n",
    "            '''para formato 2'''\n",
    "            df0_res = leer2(ruta_archivo)\n",
    "        else:\n",
    "            '''para formato 3'''\n",
    "            df0_res = leer3(ruta_archivo)\n",
    "            \n",
    "    \n",
    "    '''columna fecha'''                \n",
    "    df0_res['fecha']=df0_res['anio'].astype(str)+'-'+df0_res['mes'].astype(str)+'-'+df0_res['dia'].astype(str)\n",
    "    df0_res['fecha']=pd.to_datetime(df0_res['fecha'])\n",
    "    \n",
    "    '''reordenar las columnas'''\n",
    "    df0_res = df0_res.reindex(['fecha','pp','tmax','tmin','tmed','hmed'], axis=1)\n",
    "    \n",
    "    '''grabar el resultado en la direccion especificada'''\n",
    "    ran_fech = '_'+str(df0_res['fecha'].iloc[0].year)+str(df0_res['fecha'].iloc[0].month)+'_'+str(df0_res['fecha'].iloc[-1].year)+str(df0_res['fecha'].iloc[-1].month)\n",
    "    nombre = str(dflista['id'][i])+'_'+dflista['depto'][i]+'_'+dflista['estacion'][i]+ran_fech+'.csv'\n",
    "    ruta_guardar = '../datos/1.0.formato_csv/'+nombre\n",
    "    grabar(df0_res, ruta_guardar)\n",
    "    \n",
    "    '''guardar el nombre de los archivos en estaciones_senamhi.csv'''\n",
    "    #dflista['archivo_csv'][i] = nombre\n",
    "    dflista.loc[i,'archivo_csv'] = nombre \n",
    "\n",
    "    '''Grabar resultados'''\n",
    "    grabar(dflista, path_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e6dbb",
   "metadata": {},
   "source": [
    "### Completar información de estaciones: Challapata y Curahuara\n",
    "- Para estación de Challapata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b0abbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''leer archivo estaciones_senamhi.csv'''\n",
    "ruta_arch = '../datos/1.0.Estaciones/estaciones_senamhi.csv'\n",
    "dflista = pd.read_csv(path_file)\n",
    "\n",
    "consul1 = dflista [dflista ['estacion'] == 'challapata'].index\n",
    "ruta_chall0 = '../datos/1.0.formato_csv/'+dflista['archivo_csv'].iloc[consul1[0]]\n",
    "ruta_chall1 = '../datos/1.0.formato_csv/'+dflista['archivo_csv'].iloc[consul1[1]]\n",
    "\n",
    "'''leer los archivos a concatenar'''\n",
    "df_challapata0 = pd.read_csv(ruta_chall0)\n",
    "df_challapata1 = pd.read_csv(ruta_chall1)\n",
    "\n",
    "\n",
    "'''eliminar las filas del 2011 en df_challapata1'''\n",
    "indice = df_challapata1[(df_challapata1['fecha'] == '2011-12-31')].index\n",
    "df_challapata1.drop(range(0,indice[0]+1), inplace = True, axis = 0)\n",
    "\n",
    "'''concatenar challapata0 y challapata1'''\n",
    "df_challapata = pd.concat([df_challapata0, df_challapata1])\n",
    "df_challapata.reset_index(drop = True, inplace = True)\n",
    "\n",
    "'''guardar'''\n",
    "nombre_ch = '120_oruro_challapata_19424_20182.csv'\n",
    "path_f3 = '../datos/1.0.formato_csv/'+nombre_ch\n",
    "df_challapata.to_csv(path_f3, index = False)\n",
    "\n",
    "\n",
    "# chall = pd.DataFrame()\n",
    "# chall = chall.append(dflista.iloc[consul1[0]])\n",
    "# chall.reset_index(drop = True, inplace = True)\n",
    "# chall.drop(['codigo','nom_archivo','formato'], inplace = True, axis = 1)\n",
    "# chall.loc[0,'id']=116\n",
    "# chall.loc[0,'archivo_csv']=nombre_ch\n",
    "\n",
    "# dflista = dflista.append(chall)\n",
    "# dflista.drop([consul1[0], consul1[1]], inplace = True, axis = 0)\n",
    "# dflista.drop(['nom_archivo','formato'], inplace = True, axis = 1)\n",
    "# dflista.reset_index(drop = True, inplace = True)\n",
    "# dflista['id']=dflista['id'].astype(int)\n",
    "# dflista['altitud']=dflista['altitud'].astype(int)\n",
    "\n",
    "\n",
    "# path_f4 = '../datos/1.0.Estaciones/estaciones_senamhi_generado.csv'\n",
    "# dflista.to_csv(path_f4, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b79b6b",
   "metadata": {},
   "source": [
    "- Para estación de Curahuara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a889ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''leer archivo estaciones_senamhi.csv'''\n",
    "ruta_arch = '../datos/1.0.Estaciones/estaciones_senamhi.csv'\n",
    "dflista = pd.read_csv(path_file)\n",
    "\n",
    "consul2 = dflista [dflista ['estacion'] == 'curahuara'].index\n",
    "ruta_curah0 = '../datos/1.0.formato_csv/'+dflista['archivo_csv'].iloc[consul2[0]]\n",
    "ruta_curah1 = '../datos/1.0.formato_csv/'+dflista['archivo_csv'].iloc[consul2[1]]\n",
    "\n",
    "'''leer los archivos a concatenar'''\n",
    "df_curahuara0 = pd.read_csv(ruta_curah0)\n",
    "df_curahuara1 = pd.read_csv(ruta_curah1)\n",
    "\n",
    "\n",
    "'''Crear un DF vacio para el 2012'''\n",
    "col = df_curahuara0.columns\n",
    "df_curahuara2 = pd.DataFrame(columns=col)\n",
    "\n",
    "'''crear una columna con las fechas dentro el rango'''\n",
    "df_curahuara2['fecha'] = pd.date_range(start='2012-01-01',end='2012-12-31')\n",
    "df_curahuara2['fecha'] = pd.to_datetime(df_curahuara2['fecha']).dt.date\n",
    "\n",
    "df_curahuara = pd.concat([df_curahuara0, df_curahuara2, df_curahuara1])\n",
    "df_curahuara.reset_index(drop = True, inplace = True)\n",
    "\n",
    "nombre_cu = '121_oruro_curahuara_19759_20193.csv'\n",
    "path_f4 = '../datos/1.0.formato_csv/'+nombre_cu\n",
    "df_curahuara.to_csv(path_f4, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6c44e",
   "metadata": {},
   "source": [
    "- Crear \"estaciones_senamhi_generado.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91e7a174",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chall = pd.DataFrame()\n",
    "chall = chall.append(dflista.iloc[consul1[0]])\n",
    "chall.reset_index(drop = True, inplace = True)\n",
    "chall.drop(['codigo','nom_archivo','formato'], inplace = True, axis = 1)\n",
    "chall.loc[0,'id']=120\n",
    "chall.loc[0,'archivo_csv']=nombre_ch\n",
    "\n",
    "consul2 = dflista [dflista ['estacion'] == 'curahuara'].index\n",
    "curah = pd.DataFrame()\n",
    "curah = curah.append(dflista.iloc[consul2[0]])\n",
    "curah.reset_index(drop = True, inplace = True)\n",
    "curah.drop(['codigo','nom_archivo','formato'], inplace = True, axis = 1)\n",
    "curah.loc[0,'id']=121\n",
    "curah.loc[0,'archivo_csv']=nombre_cu\n",
    "\n",
    "\n",
    "dflista = dflista.append(chall)\n",
    "\n",
    "dflista = dflista.append(curah)\n",
    "\n",
    "dflista.drop([consul1[0], consul1[1],consul2[0], consul2[1]], inplace = True, axis = 0)\n",
    "dflista.drop(['nom_archivo','formato'], inplace = True, axis = 1)\n",
    "dflista.reset_index(drop = True, inplace = True)\n",
    "dflista['id']=dflista['id'].astype(int)\n",
    "dflista['altitud']=dflista['altitud'].astype(int)\n",
    "dflista['codigo']=dflista['codigo'].fillna(0)\n",
    "dflista['codigo']=dflista['codigo'].astype(int)\n",
    "\n",
    "path_f3 = '../datos/1.0.Estaciones/estaciones_senamhi_generado.csv'\n",
    "dflista.to_csv(path_f3, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9af2877e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>estacion</th>\n",
       "      <th>depto</th>\n",
       "      <th>altitud</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>codigo</th>\n",
       "      <th>archivo_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>aeropuerto</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3702</td>\n",
       "      <td>-67.079722</td>\n",
       "      <td>-17.952778</td>\n",
       "      <td>4012</td>\n",
       "      <td>100_oruro_aeropuerto_19431_202012.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>andamarca</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3762</td>\n",
       "      <td>-67.506389</td>\n",
       "      <td>-18.771944</td>\n",
       "      <td>4001</td>\n",
       "      <td>101_oruro_andamarca_19757_202010.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>antequera</td>\n",
       "      <td>oruro</td>\n",
       "      <td>4057</td>\n",
       "      <td>-66.882900</td>\n",
       "      <td>-18.492900</td>\n",
       "      <td>4080</td>\n",
       "      <td>102_oruro_antequera_20131_20195.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>chillca</td>\n",
       "      <td>oruro</td>\n",
       "      <td>4025</td>\n",
       "      <td>-66.813889</td>\n",
       "      <td>-17.836944</td>\n",
       "      <td>4026</td>\n",
       "      <td>105_oruro_chillca_19951_202012.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>choquecota</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3867</td>\n",
       "      <td>-67.899000</td>\n",
       "      <td>-18.097000</td>\n",
       "      <td>0</td>\n",
       "      <td>106_oruro_choquecota_19911_20098.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107</td>\n",
       "      <td>corque</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3758</td>\n",
       "      <td>-67.678611</td>\n",
       "      <td>-18.343889</td>\n",
       "      <td>4066</td>\n",
       "      <td>107_oruro_corque_20128_20181.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108</td>\n",
       "      <td>cosapa</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3906</td>\n",
       "      <td>-68.706389</td>\n",
       "      <td>-18.177778</td>\n",
       "      <td>4005</td>\n",
       "      <td>108_oruro_cosapa_19758_202010.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>111</td>\n",
       "      <td>huachacalla</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3746</td>\n",
       "      <td>-68.257222</td>\n",
       "      <td>-18.787222</td>\n",
       "      <td>4009</td>\n",
       "      <td>111_oruro_huachacalla_19758_20049.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112</td>\n",
       "      <td>huayllamarca</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3873</td>\n",
       "      <td>-67.939722</td>\n",
       "      <td>-17.835556</td>\n",
       "      <td>4010</td>\n",
       "      <td>112_oruro_huayllamarca_19904_20214.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>113</td>\n",
       "      <td>quillacas</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3724</td>\n",
       "      <td>-66.959722</td>\n",
       "      <td>-19.230000</td>\n",
       "      <td>0</td>\n",
       "      <td>113_oruro_quillacas_19758_201112.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>114</td>\n",
       "      <td>san-martin</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3712</td>\n",
       "      <td>-67.599167</td>\n",
       "      <td>-19.275000</td>\n",
       "      <td>4019</td>\n",
       "      <td>114_oruro_san-martin_197511_20212.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>115</td>\n",
       "      <td>soracachi</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3802</td>\n",
       "      <td>-67.024750</td>\n",
       "      <td>-17.768111</td>\n",
       "      <td>4083</td>\n",
       "      <td>115_oruro_soracachi_20141_20195.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>116</td>\n",
       "      <td>todo-santos</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3805</td>\n",
       "      <td>-68.715278</td>\n",
       "      <td>-19.007778</td>\n",
       "      <td>4028</td>\n",
       "      <td>116_oruro_todo-santos_19758_20214.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>117</td>\n",
       "      <td>toledo</td>\n",
       "      <td>oruro</td>\n",
       "      <td>4038</td>\n",
       "      <td>-67.406000</td>\n",
       "      <td>-18.179000</td>\n",
       "      <td>4038</td>\n",
       "      <td>117_oruro_toledo_20142_20215.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>118</td>\n",
       "      <td>turco</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3842</td>\n",
       "      <td>-68.369000</td>\n",
       "      <td>-18.346000</td>\n",
       "      <td>0</td>\n",
       "      <td>118_oruro_turco_19758_20154.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>119</td>\n",
       "      <td>ucumasi</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3764</td>\n",
       "      <td>-67.424722</td>\n",
       "      <td>-19.130278</td>\n",
       "      <td>4023</td>\n",
       "      <td>119_oruro_ucumasi_19758_20213.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200</td>\n",
       "      <td>achiri</td>\n",
       "      <td>lapaz</td>\n",
       "      <td>3880</td>\n",
       "      <td>-68.999400</td>\n",
       "      <td>-17.211700</td>\n",
       "      <td>0</td>\n",
       "      <td>200_lapaz_achiri_19751_202112.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>201</td>\n",
       "      <td>ayoayo</td>\n",
       "      <td>lapaz</td>\n",
       "      <td>3888</td>\n",
       "      <td>-68.008300</td>\n",
       "      <td>-17.094200</td>\n",
       "      <td>0</td>\n",
       "      <td>201_lapaz_ayoayo_19531_202112.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202</td>\n",
       "      <td>berenguela</td>\n",
       "      <td>lapaz</td>\n",
       "      <td>4120</td>\n",
       "      <td>-69.214167</td>\n",
       "      <td>-17.288889</td>\n",
       "      <td>0</td>\n",
       "      <td>202_lapaz_berenguela_19761_202112.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>203</td>\n",
       "      <td>calacoto</td>\n",
       "      <td>lapaz</td>\n",
       "      <td>3826</td>\n",
       "      <td>-68.635600</td>\n",
       "      <td>-17.280600</td>\n",
       "      <td>0</td>\n",
       "      <td>203_lapaz_calacoto_19701_202112.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>204</td>\n",
       "      <td>catacora</td>\n",
       "      <td>lapaz</td>\n",
       "      <td>4253</td>\n",
       "      <td>-69.486389</td>\n",
       "      <td>-17.158611</td>\n",
       "      <td>0</td>\n",
       "      <td>204_lapaz_catacora_19921_202112.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>205</td>\n",
       "      <td>conchamarca</td>\n",
       "      <td>lapaz</td>\n",
       "      <td>3965</td>\n",
       "      <td>-67.455278</td>\n",
       "      <td>-17.376944</td>\n",
       "      <td>0</td>\n",
       "      <td>205_lapaz_conchamarca_19751_202112.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>120</td>\n",
       "      <td>challapata</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3733</td>\n",
       "      <td>-66.777778</td>\n",
       "      <td>-18.895833</td>\n",
       "      <td>0</td>\n",
       "      <td>120_oruro_challapata_19424_20182.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>121</td>\n",
       "      <td>curahuara</td>\n",
       "      <td>oruro</td>\n",
       "      <td>3917</td>\n",
       "      <td>-68.414444</td>\n",
       "      <td>-17.838889</td>\n",
       "      <td>0</td>\n",
       "      <td>121_oruro_curahuara_19759_20193.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id      estacion  depto  altitud        lon        lat  codigo  \\\n",
       "0   100    aeropuerto  oruro     3702 -67.079722 -17.952778    4012   \n",
       "1   101     andamarca  oruro     3762 -67.506389 -18.771944    4001   \n",
       "2   102     antequera  oruro     4057 -66.882900 -18.492900    4080   \n",
       "3   105       chillca  oruro     4025 -66.813889 -17.836944    4026   \n",
       "4   106    choquecota  oruro     3867 -67.899000 -18.097000       0   \n",
       "5   107        corque  oruro     3758 -67.678611 -18.343889    4066   \n",
       "6   108        cosapa  oruro     3906 -68.706389 -18.177778    4005   \n",
       "7   111   huachacalla  oruro     3746 -68.257222 -18.787222    4009   \n",
       "8   112  huayllamarca  oruro     3873 -67.939722 -17.835556    4010   \n",
       "9   113     quillacas  oruro     3724 -66.959722 -19.230000       0   \n",
       "10  114    san-martin  oruro     3712 -67.599167 -19.275000    4019   \n",
       "11  115     soracachi  oruro     3802 -67.024750 -17.768111    4083   \n",
       "12  116   todo-santos  oruro     3805 -68.715278 -19.007778    4028   \n",
       "13  117        toledo  oruro     4038 -67.406000 -18.179000    4038   \n",
       "14  118         turco  oruro     3842 -68.369000 -18.346000       0   \n",
       "15  119       ucumasi  oruro     3764 -67.424722 -19.130278    4023   \n",
       "16  200        achiri  lapaz     3880 -68.999400 -17.211700       0   \n",
       "17  201        ayoayo  lapaz     3888 -68.008300 -17.094200       0   \n",
       "18  202    berenguela  lapaz     4120 -69.214167 -17.288889       0   \n",
       "19  203      calacoto  lapaz     3826 -68.635600 -17.280600       0   \n",
       "20  204      catacora  lapaz     4253 -69.486389 -17.158611       0   \n",
       "21  205   conchamarca  lapaz     3965 -67.455278 -17.376944       0   \n",
       "22  120    challapata  oruro     3733 -66.777778 -18.895833       0   \n",
       "23  121     curahuara  oruro     3917 -68.414444 -17.838889       0   \n",
       "\n",
       "                               archivo_csv  \n",
       "0    100_oruro_aeropuerto_19431_202012.csv  \n",
       "1     101_oruro_andamarca_19757_202010.csv  \n",
       "2      102_oruro_antequera_20131_20195.csv  \n",
       "3       105_oruro_chillca_19951_202012.csv  \n",
       "4     106_oruro_choquecota_19911_20098.csv  \n",
       "5         107_oruro_corque_20128_20181.csv  \n",
       "6        108_oruro_cosapa_19758_202010.csv  \n",
       "7    111_oruro_huachacalla_19758_20049.csv  \n",
       "8   112_oruro_huayllamarca_19904_20214.csv  \n",
       "9     113_oruro_quillacas_19758_201112.csv  \n",
       "10   114_oruro_san-martin_197511_20212.csv  \n",
       "11     115_oruro_soracachi_20141_20195.csv  \n",
       "12   116_oruro_todo-santos_19758_20214.csv  \n",
       "13        117_oruro_toledo_20142_20215.csv  \n",
       "14         118_oruro_turco_19758_20154.csv  \n",
       "15       119_oruro_ucumasi_19758_20213.csv  \n",
       "16       200_lapaz_achiri_19751_202112.csv  \n",
       "17       201_lapaz_ayoayo_19531_202112.csv  \n",
       "18   202_lapaz_berenguela_19761_202112.csv  \n",
       "19     203_lapaz_calacoto_19701_202112.csv  \n",
       "20     204_lapaz_catacora_19921_202112.csv  \n",
       "21  205_lapaz_conchamarca_19751_202112.csv  \n",
       "22    120_oruro_challapata_19424_20182.csv  \n",
       "23     121_oruro_curahuara_19759_20193.csv  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dflista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489de71a",
   "metadata": {},
   "source": [
    "### Datos entre limites d1 <= datos <= d2, revisar los archivos CSV en busca de strings y convertirlos a NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18433bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Se define Periodo de Análisis: f1=Fecha de Inicio y f2=Fecha de Finalización '''\n",
    "f1=pd.Timestamp(1981, 1, 1)\n",
    "f2=pd.Timestamp(2020, 12, 31)\n",
    "\n",
    "def genera_rango (d1, d2, columnas, frontera ):\n",
    "    vacio = pd.DataFrame(columns = columnas)\n",
    "    vacio['fecha']=pd.date_range(start=d1,end=d2,closed=frontera)\n",
    "    return vacio\n",
    "    \n",
    "def limite (d1, d2, data):\n",
    "    data['fecha'] = pd.to_datetime(data['fecha'])\n",
    "    if (d1 < data['fecha'].iloc[0]):\n",
    "        datainf = genera_rango(d1, data['fecha'].iloc[0], data.columns, 'left')\n",
    "        data = datainf.append(data, ignore_index = True)\n",
    "    if (data['fecha'].iloc[-1] < d2):\n",
    "        datasup = genera_rango(data['fecha'].iloc[-1], d2, data.columns, 'right')\n",
    "        data = data.append(datasup, ignore_index = True)\n",
    "    if (d1 > data['fecha'].iloc[0]):\n",
    "        indiceinf = data[(data['fecha'] == d1)].index\n",
    "        data.drop(range(0,indiceinf[0]), inplace = True, axis = 0)\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "    if (data['fecha'].iloc[-1] > d2):\n",
    "        indicesup = data[(data['fecha'] == d2)].index\n",
    "        data.drop(range(indicesup[-1]+1,data.shape[0]), inplace = True, axis = 0)\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "'''metodo para cambiar las cadenas en nan y los numeros en float'''\n",
    "def cambiar(data):\n",
    "    tam = data.shape[0]\n",
    "    for x in range (0, tam):\n",
    "        for y in range (1, 6):\n",
    "            try:\n",
    "                data.iloc[x,y] = float(data.iloc[x,y])\n",
    "            except ValueError:\n",
    "                data.iloc[x,y] = np.nan\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ab9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_f3 = '../datos/1.0.Estaciones/estaciones_senamhi_generado.csv'\n",
    "dflista = pd.read_csv(path_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2e0d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflista['archivo_csv_corregido'] = ''\n",
    "\n",
    "for p in dflista['archivo_csv']:\n",
    "    pin = '../datos/1.0.formato_csv/'+p\n",
    "    file = pd.read_csv(pin)\n",
    "    rfile = limite(f1,f2,file) \n",
    "    cfile = cambiar(rfile)\n",
    "    \n",
    "    cad=p.split('_')\n",
    "    pmod='obs_'+cad[0]+'_'+cad[2]+'.csv'\n",
    "    pout = '../datos/1.0.formato_csv_corregido/'+pmod\n",
    "    cfile.to_csv(pout, index = False)\n",
    "    \n",
    "    indice = dflista[dflista['archivo_csv'] == p].index[0]\n",
    "    dflista.at[indice, 'archivo_csv_corregido'] = pmod\n",
    "\n",
    "dflista = dflista.sort_values('id', ascending=True)\n",
    "dflista.reset_index(drop=True, inplace=True)\n",
    "dflista.to_csv(path_f3, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf361ca",
   "metadata": {},
   "source": [
    "## Para generar dataframe para cada variable meteorológica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "509657de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creardf(data, col):\n",
    "    dat = pd.DataFrame()\n",
    "    dat[col] = data[col]\n",
    "    return dat\n",
    "\n",
    "def guardar(data, nom, path='../datos/1.0.variables/'):\n",
    "    pth = path + nom\n",
    "    data.to_csv(pth, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd81b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_f3 = '../datos/1.0.Estaciones/estaciones_senamhi_generado.csv'\n",
    "dflista = pd.read_csv(path_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49fda6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('../datos/1.0.formato_csv_corregido/obs_100_aeropuerto.csv')\n",
    "\n",
    "dfpp = creardf(temp,['fecha'])\n",
    "dftmx = creardf(temp,['fecha'])\n",
    "dftmn = creardf(temp,['fecha'])\n",
    "dftmd = creardf(temp,['fecha'])\n",
    "dfhmd = creardf(temp,['fecha'])\n",
    "nom_col = ['fecha']\n",
    "\n",
    "for p in dflista['archivo_csv_corregido']:\n",
    "    pin = '../datos/1.0.formato_csv_corregido/' + p\n",
    "    file = pd.read_csv(pin)\n",
    "    dfpp = pd.concat([dfpp, file['pp']], axis=1)\n",
    "    dftmx = pd.concat([dftmx, file['tmax']], axis=1)\n",
    "    dftmn = pd.concat([dftmn, file['tmin']], axis=1)\n",
    "    dftmd = pd.concat([dftmd, file['tmed']], axis=1)\n",
    "    dfhmd = pd.concat([dfhmd, file['hmed']], axis=1)\n",
    "    \n",
    "    cad = p.split('_')\n",
    "    nom_col.append(str(cad[1]))\n",
    "    \n",
    "dfpp.columns = nom_col\n",
    "dftmx.columns = nom_col\n",
    "dftmn.columns = nom_col\n",
    "dftmd.columns = nom_col\n",
    "dfhmd.columns = nom_col\n",
    "\n",
    "guardar(dfpp, 'obs_diario_pp.csv')\n",
    "guardar(dftmx, 'obs_diario_tmax.csv')\n",
    "guardar(dftmn, 'obs_diario_tmin.csv')\n",
    "guardar(dftmd, 'obs_diario_tmed.csv')\n",
    "guardar(dfhmd, 'obs_diario_hmed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "095375ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=3101, microseconds=290862)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Tiempo de ejecucion'''\n",
    "t1 = datetime.datetime.now()\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73c00011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100  101  111  117   120   121\n",
      "0   0.0  0.0  0.0  NaN   0.0   7.5\n",
      "1   0.0  1.5  0.0  NaN   0.0   0.0\n",
      "2   0.0  0.0  2.3  NaN  12.0   0.0\n",
      "3   2.8  0.0  1.2  NaN  13.3  14.5\n",
      "4  23.9  0.8  0.0  NaN   0.0   6.5\n"
     ]
    }
   ],
   "source": [
    "'''mostrar dataframe de precipitacion'''\n",
    "print(dfpp[['100','101','111','117','120','121']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00abde76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100  116  117   120   201   203\n",
      "0  19.8  NaN  NaN  19.5  17.2  20.2\n",
      "1  20.0  NaN  NaN  21.0  17.9  21.8\n",
      "2  19.8  NaN  NaN  23.0  17.8  16.4\n",
      "3  18.6  NaN  NaN  16.4  14.8  18.0\n",
      "4  16.8  NaN  NaN  17.0  12.5  17.0\n"
     ]
    }
   ],
   "source": [
    "'''mostrar dataframe de temperatura máxima'''\n",
    "print(dftmx[['100','116','117','120','201','203']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86d513d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   100  116  117  120  201  203\n",
      "0  6.8  NaN  NaN  5.6  3.0  3.6\n",
      "1  7.9  NaN  NaN  7.5  2.9  3.0\n",
      "2  5.1  NaN  NaN  6.5  5.3  4.9\n",
      "3  5.3  NaN  NaN  8.1  4.1  6.2\n",
      "4  7.1  NaN  NaN  5.2  4.5  5.3\n"
     ]
    }
   ],
   "source": [
    "'''mostrar dataframe de temperatura mínima'''\n",
    "print(dftmn[['100','116','117','120','201','203']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c61594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id    estacion  depto  altitud        lon        lat\n",
      "0  100  aeropuerto  oruro     3702 -67.079722 -17.952778\n",
      "1  101   andamarca  oruro     3762 -67.506389 -18.771944\n",
      "2  102   antequera  oruro     4057 -66.882900 -18.492900\n",
      "3  105     chillca  oruro     4025 -66.813889 -17.836944\n",
      "4  106  choquecota  oruro     3867 -67.899000 -18.097000\n"
     ]
    }
   ],
   "source": [
    "'''datos de las estaciones'''\n",
    "print(dflista[['id','estacion','depto','altitud','lon','lat']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8011d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
