{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f97e9e",
   "metadata": {},
   "source": [
    "# Convertir archivos excel de SENAMHI a archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0eaa09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'instalar openpyxl para abrir varias hojas de un libro de excel'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''instalar openpyxl para abrir varias hojas de un libro de excel'''\n",
    "# %pip install openpyxl\n",
    "# %pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104fd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from calendar import monthrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e18ec02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876af200",
   "metadata": {},
   "source": [
    "# Convertir de formato obtenido a fomato CSV\n",
    "\n",
    "Leer los datos del archivo CSV 'estaciones_senamhi'.\n",
    "Las columnas que nos interesan:\n",
    " - path_format contiene las rutas relativas de los archivos,\n",
    " - path_csv contiene las rutas relativas para guardar los arvhivos resultantes\n",
    " - f contiene el tipo de formato que tiene cada archivo <1 , 2 , 3>\n",
    "\n",
    "## Formato 1, 2, 3 a formato CSV\n",
    "Definimos los metodos para las diferentes operaciones y cálculos\n",
    "Para un dataframe de la forma\n",
    "\n",
    "| anio = 2003 | | | | | | | | | | | | | |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---|\n",
    "| DIA | ENE | FEB | MAR | ABR | MAY | JUN | JUL | AGO | SEP | OCT | NOV | DIC | TOTAL |\n",
    "|1|  1  |  2  |  3  |  4  |     |  2  |  3  |  3  |  5  |  1  |     |     |  x|\n",
    "|2|  0  |  0  |  0  |  0  |  0  |  9  |  8  |  5  |  3  |     |     |     |  y|\n",
    "|...| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ...|\n",
    "|30  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  z|\n",
    "|31  |  5  |  1  |     |     |  5  |  1  |     |     |  5  |  1  |     |     |  w|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be9d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''devuelve la cadena \"2003\" convertida en INT, enviadole un DF y el Indice donde se encuentra'''\n",
    "def es_anio(data, indice):\n",
    "    '''recuperar el valor del indice y columna'''\n",
    "    cadena = data.iloc[indice,0]\n",
    "    '''separa la cadena en base al caracter \" \" (espacio)'''\n",
    "    an = cadena.split(' ')\n",
    "    '''devulve el anio, previamente lo convierte en Entero'''\n",
    "    return int(an[1])\n",
    "\n",
    "'''devuelve los datos diarios de cada mes en el anio especificado, traspuestos al formato de entrada'''\n",
    "def anio_datos (data, indice):\n",
    "    '''declarar fila(indice) de inicio y fin de los datos del anio'''\n",
    "    filaini = indice + 2\n",
    "    filafin = indice + 33\n",
    "    '''extraer los datos contenidos entre los limites'''\n",
    "    df1 = data.iloc[filaini:filafin , 1:13]\n",
    "    '''resetear el indice'''\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    '''transponer los datos obtenidos y resetear el indice'''\n",
    "    df2=df1.T\n",
    "    df2.reset_index(drop=True, inplace = True)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89824e0",
   "metadata": {},
   "source": [
    "#### La siguiente función devuelve un dataframe de la forma\n",
    "\n",
    "| anio | mes |  1  |  2  | ... | 30 | 31|\n",
    "| --- | --- | --- | --- | --- | --- | ---|\n",
    "| yyyy | m01 |  0  |     | ... |  0 |  1|\n",
    "| yyyy | m02 |  1  |  0  | ... |    |  2|\n",
    "| .... | ... | ... | ... | ... | .. | ..|\n",
    "| yyyy | m11 |  0  |  0  | ... |  0 |  0|\n",
    "| yyyy | m12 |     |  0  | ... |    |  2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8458a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anio_comple(data, indice):\n",
    "    '''crear un df vacio con las columnas anio y mes'''\n",
    "    am = pd.DataFrame(columns = ['anio', 'mes'])\n",
    "    '''rellenar las columnas mes y anio'''\n",
    "    am ['mes'] = np.arange(1, 13)\n",
    "    am ['anio'] = es_anio(data, indice)\n",
    "    '''recuperar el df transpuesto'''\n",
    "    dfa = anio_datos(data, indice)\n",
    "    df = pd.concat([am, dfa], axis = 1)\n",
    "    return df\n",
    "\n",
    "'''recorrer todo el libro para recuperar todos los anios'''\n",
    "def medida(data):\n",
    "    i = 0\n",
    "    '''cantidad total de filas en el df'''\n",
    "    n = data.shape [0]\n",
    "    dfall = pd.DataFrame()\n",
    "    while i<n:\n",
    "        dfanio = anio_comple(data, i)\n",
    "        dfall = pd.concat([dfall, dfanio], axis = 0)\n",
    "        dfall.reset_index(drop = True, inplace = True)\n",
    "        i += 39\n",
    "    return dfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "685aadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''funcion que devuelve la fecha de inicio y finalizacion de los datos disponibles de un df'''\n",
    "def cont_val(df1):\n",
    "    if min(df1.shape)!=0:\n",
    "        amin = df1['anio'].min()\n",
    "        amax = df1['anio'].max()\n",
    "        mmin = df1[df1['anio']==amin]['mes'].min()\n",
    "        mmax = df1[df1['anio']==amax]['mes'].max()\n",
    "        dmax = max(monthrange(amax, mmax))\n",
    "        fecha1=datetime.date(amin, mmin, 1)\n",
    "        fecha2=datetime.date(amax, mmax, dmax)\n",
    "    else:\n",
    "        fecha1 = pd.NaT\n",
    "        fecha2 = pd.NaT\n",
    "    return [fecha1, fecha2]\n",
    "\n",
    "'''funcion que genera el df de cada medicion'''\n",
    "def generar_df(d1, d2, df_medicion):\n",
    "    var_fijas = [\"anio\",\"mes\"]\n",
    "    var_melt = df_medicion.columns.difference(pd.Index(var_fijas))\n",
    "    df_dia= pd.melt(df_medicion,id_vars=var_fijas,value_vars=var_melt, var_name=\"dia\",value_name=\"valor\").sort_values(by=[\"anio\",\"mes\",\"dia\"]).reset_index(drop=True)\n",
    "    df_dia['dia']=df_dia['dia'].astype(int)\n",
    "    df_datos = df_dia.sort_values(by=[\"anio\",\"mes\",\"dia\"]).reset_index(drop=True)\n",
    "    \n",
    "    '''crear un dataframe vacio con las columnas anio, mes, dia, value'''\n",
    "    df1 = pd.DataFrame(columns=['anio','mes','dia','valor'])\n",
    "\n",
    "    '''crear una columna con las fechas dentro el rango'''\n",
    "    df1['fecha']=pd.date_range(start=d1,end=d2)\n",
    "\n",
    "    '''asignar las columnas de anio, mes, dia con los valores del rango'''\n",
    "    df1['anio'] = df1['fecha'].dt.year\n",
    "    df1['mes'] = df1['fecha'].dt.month\n",
    "    df1['dia'] = df1['fecha'].dt.day\n",
    "\n",
    "    '''eliminar la columna fecha'''\n",
    "    df1.drop(['fecha'], axis=1, inplace=True)\n",
    "    \n",
    "    '''crear listas para cada ciclo'''\n",
    "    rango_anio = list(df1['anio'].unique())\n",
    "    for x in rango_anio:\n",
    "        rango_mes = list(df1[df1['anio']==x]['mes'].unique())\n",
    "        for y in rango_mes:\n",
    "            rango_dia = list(df1[(df1['anio']==x) & (df1['mes']==y)]['dia'].unique())\n",
    "            for z in rango_dia:\n",
    "                '''asignar el subdataframe con la condicion'''\n",
    "                aux = pd.DataFrame()\n",
    "                aux = df_datos[(df_datos['anio']==x) & (df_datos['mes']==y) & (df_datos['dia']==z)]\n",
    "                '''evaluar el tamaño del subdataframe'''\n",
    "                if min(aux.shape)!=0:\n",
    "                    '''reiniciar el indice del subdataframe'''\n",
    "                    aux.reset_index(drop=True, inplace=True)\n",
    "                    '''obtener el indice de la fila con la fecha requerida y asignar el valor correspondiente'''\n",
    "                    indice = df1.index[(df1['anio']==x) & (df1['mes']==y) & (df1['dia']==z)]\n",
    "                    df1.loc[indice, 'valor'] = aux.loc[0, 'valor']\n",
    "    return df1\n",
    "\n",
    "\n",
    "'''leer datos desde un archivo con formato 1'''\n",
    "def leer1(path_f01):\n",
    "    '''leer los datos desde un xlsx, las primeras 7 hojas'''\n",
    "    cab_1=['anio', 'mes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "    hoj_1=['CODP1', 'CODP2', 'CODP3', 'CODP4', 'CODP5', 'CODP6', 'CODP7']\n",
    "    libro = pd.read_excel(path_f01, sheet_name=hoj_1, skiprows=5, names=cab_1)\n",
    "    return libro\n",
    "\n",
    "'''retorna el archivo csv, enviando el libro como datos'''\n",
    "def asignar1(data):\n",
    "    '''asignar el contenido del DICTIONARY a dataframes'''\n",
    "    dfpp=pd.DataFrame(data['CODP1'])\n",
    "    dftmax=pd.DataFrame(data['CODP3'])\n",
    "    dftmin=pd.DataFrame(data['CODP2'])\n",
    "    dftmed=pd.DataFrame(data['CODP4'])\n",
    "    dfhmed=pd.DataFrame(data['CODP5'])\n",
    "    dfhmax=pd.DataFrame(data['CODP6'])\n",
    "    dfhmin=pd.DataFrame(data['CODP7']) \n",
    "    \n",
    "    '''llamar a la funcion cont_val para calcular el rango de fechas'''\n",
    "    rpp = cont_val(dfpp)\n",
    "    rtmax = cont_val(dftmax)\n",
    "    rtmin = cont_val(dftmin)\n",
    "    rtmed = cont_val(dftmed)\n",
    "    rhmed = cont_val(dfhmed)\n",
    "    rhmax = cont_val(dfhmax)\n",
    "    rhmin = cont_val(dfhmin)\n",
    "    col=['fec_ini', 'fec_fin']\n",
    "    indic = ['pp', 'tmax', 'tmin', 'tmed', 'hmed', 'hmax', 'hmin']\n",
    "    df_fecha = pd.DataFrame([rpp, rtmax, rtmin, rtmed, rhmed, rhmax, rhmin], columns=col, index = indic)\n",
    "    fecha_min = min(df_fecha['fec_ini'])\n",
    "    fecha_max = max(df_fecha['fec_fin'])\n",
    "\n",
    "    '''llamar a la funcion generar_df para generar los df con la misma fecha de inicio y finalizacion'''\n",
    "    rpp = generar_df(fecha_min, fecha_max, dfpp)\n",
    "    rtmax = generar_df(fecha_min, fecha_max, dftmax)\n",
    "    rtmin = generar_df(fecha_min, fecha_max, dftmin)\n",
    "    rtmed = generar_df(fecha_min, fecha_max, dftmed)\n",
    "    rhmed = generar_df(fecha_min, fecha_max, dfhmed)\n",
    "    rhmax = generar_df(fecha_min, fecha_max, dfhmax)\n",
    "    rhmin = generar_df(fecha_min, fecha_max, dfhmin)\n",
    "    \n",
    "    '''concatenar los resultados parciales'''\n",
    "    df_estacion1 = pd.concat([rpp['anio'], rpp['mes'], rpp['dia'], rpp['valor'], rtmax['valor'], rtmin['valor'], rtmed['valor'], rhmax['valor'], rhmin['valor'], rhmed['valor']], axis=1)\n",
    "\n",
    "    '''cambiar los nombres de las columnas'''\n",
    "    df_estacion1.columns = ['anio','mes','dia','pp','tmax','tmin','tmed','hmax','hmin','hmed']    \n",
    "    \n",
    "    return df_estacion1\n",
    "\n",
    "\n",
    "'''metodo para cambiar de nombre las columnas(nomcols) de un df(data) que no tiene datos'''\n",
    "def col_nom(data, nomcols):\n",
    "    '''si el df esta vacio'''\n",
    "    if data.shape[0] != 0:\n",
    "        '''retorna el df actualizado'''\n",
    "        data.columns = nomcols\n",
    "        return data\n",
    "    else:\n",
    "        '''retorna un df vacio con columnas'''\n",
    "        data0 = pd.DataFrame(columns = nomcols)\n",
    "        return data0\n",
    "\n",
    "\n",
    "'''leer datos de un archivo con formato 2'''\n",
    "def leer2(path_f02):\n",
    "    '''leer los datos desde un xlsx, las primeras 7 hojas'''\n",
    "    hoj_2 = ['Hoja1', 'Hoja2', 'Hoja3', 'Hoja4', 'Hoja5', 'Hoja6', 'Hoja7']\n",
    "    try:\n",
    "        libro = pd.read_excel(path_f02, header = None, sheet_name = hoj_2, skiprows = 4)\n",
    "    except ValueError:\n",
    "        libro = pd.read_excel(path_f02, header = None, sheet_name = 'Hoja1', skiprows = 4)\n",
    "        \n",
    "    '''asignar el contenido del DICTIONARY a dataframes'''\n",
    "    if isinstance (libro, dict):\n",
    "        dpp=pd.DataFrame(libro['Hoja1'])\n",
    "        dtmax=pd.DataFrame(libro['Hoja2'])\n",
    "        dtmin=pd.DataFrame(libro['Hoja3'])\n",
    "        dtmed=pd.DataFrame(libro['Hoja4'])\n",
    "        dhmed=pd.DataFrame(libro['Hoja5'])\n",
    "        dhmax=pd.DataFrame(libro['Hoja6'])\n",
    "        dhmin=pd.DataFrame(libro['Hoja7'])\n",
    "\n",
    "    '''llamar a la funcion para generar el formato horizontal'''\n",
    "    if isinstance (libro, dict):\n",
    "        dfpp = medida(dpp)\n",
    "        dftmax = medida(dtmax)\n",
    "        dftmin = medida(dtmin)\n",
    "        dftmed = medida(dtmed)\n",
    "        dfhmed = medida(dhmed)\n",
    "        dfhmax = medida(dhmax)\n",
    "        dfhmin = medida(dhmin)\n",
    "    else:\n",
    "        dfpp = medida(libro)\n",
    "\n",
    "    '''cambiar las columnas de los df'''\n",
    "    cols = ['anio', 'mes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "\n",
    "    if isinstance (libro, dict):\n",
    "        dfpp = col_nom(dfpp, cols)\n",
    "        dftmax = col_nom(dftmax, cols)\n",
    "        dftmin = col_nom(dftmin, cols)\n",
    "        dftmed = col_nom(dftmed, cols)\n",
    "        dfhmed = col_nom(dfhmed, cols)\n",
    "        dfhmax = col_nom(dfhmax, cols)\n",
    "        dfhmin = col_nom(dfhmin, cols)\n",
    "    else:\n",
    "        dfvacio = pd.DataFrame()\n",
    "        dfpp = col_nom(dfpp, cols)\n",
    "        dftmax = col_nom(dfvacio, cols)\n",
    "        dftmin = col_nom(dfvacio, cols)\n",
    "        dftmed = col_nom(dfvacio, cols)\n",
    "        dfhmed = col_nom(dfvacio, cols)\n",
    "        dfhmax = col_nom(dfvacio, cols)\n",
    "        dfhmin = col_nom(dfvacio, cols)\n",
    "    \n",
    "    '''llamar a la funcion cont_val para calcular el rango de fechas'''\n",
    "    fecpp = cont_val(dfpp)\n",
    "    fectmax = cont_val(dftmax)\n",
    "    fectmin = cont_val(dftmin)\n",
    "    fectmed = cont_val(dftmed)\n",
    "    fechmed = cont_val(dfhmed)\n",
    "    fechmax = cont_val(dfhmax)\n",
    "    fechmin = cont_val(dfhmin)\n",
    "    col=['fec_ini', 'fec_fin']\n",
    "    indic = ['pp', 'tmax', 'tmin', 'tmed', 'hmed', 'hmax', 'hmin']\n",
    "    df_fecha = pd.DataFrame([fecpp, fectmax, fectmin, fectmed, fechmed, fechmax, fechmin], columns=col, index = indic)\n",
    "    fecha_min = min(df_fecha['fec_ini'])\n",
    "    fecha_max = max(df_fecha['fec_fin'])\n",
    "\n",
    "    '''llamar a la funcion generar_df para generar los df con la misma fecha de inicio y finalizacion'''\n",
    "    rpp = generar_df(fecha_min, fecha_max, dfpp)\n",
    "    rtmax = generar_df(fecha_min, fecha_max, dftmax)\n",
    "    rtmin = generar_df(fecha_min, fecha_max, dftmin)\n",
    "    rtmed = generar_df(fecha_min, fecha_max, dftmed)\n",
    "    rhmed = generar_df(fecha_min, fecha_max, dfhmed)\n",
    "    rhmax = generar_df(fecha_min, fecha_max, dfhmax)\n",
    "    rhmin = generar_df(fecha_min, fecha_max, dfhmin)\n",
    "\n",
    "    '''concatenar los resultados parciales'''\n",
    "    df_estacion2 = pd.concat([rpp['anio'], rpp['mes'], rpp['dia'], rpp['valor'], rtmax['valor'], rtmin['valor'], rtmed['valor'], rhmax['valor'], rhmin['valor'], rhmed['valor']], axis=1)\n",
    "    '''cambiar los nombres de las columnas'''\n",
    "    df_estacion2.columns = ['anio','mes','dia','pp','tmax','tmin','tmed','hmax','hmin','hmed']\n",
    "    \n",
    "    return df_estacion2\n",
    "\n",
    "'''leer datos de un archivo con formato 3'''\n",
    "def leer3(path_f03):\n",
    "    df03 = pd.read_csv(path_f03)\n",
    "    return df03\n",
    "\n",
    "def grabar(data, path_f):\n",
    "    ''''grabar el dataframe resultante en un archivo csv'''\n",
    "    data.to_csv(path_f, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d5645",
   "metadata": {},
   "source": [
    "### Leer archivo estaciones_senamhi.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a72eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = '../datos/estaciones_senamhi.csv'\n",
    "dflista = pd.read_csv(path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2efc4",
   "metadata": {},
   "source": [
    "### Realizar operaciones para generar archivos CSV de cada estación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e73c3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80926/2493341111.py:88: FutureWarning: Comparison of NaT with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.\n",
      "  fecha_min = min(df_fecha['fec_ini'])\n",
      "/tmp/ipykernel_80926/2493341111.py:89: FutureWarning: Comparison of NaT with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.\n",
      "  fecha_max = max(df_fecha['fec_fin'])\n",
      "/tmp/ipykernel_80926/2493341111.py:185: FutureWarning: Comparison of NaT with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.\n",
      "  fecha_min = min(df_fecha['fec_ini'])\n",
      "/tmp/ipykernel_80926/2493341111.py:186: FutureWarning: Comparison of NaT with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.\n",
      "  fecha_max = max(df_fecha['fec_fin'])\n"
     ]
    }
   ],
   "source": [
    "total_f = dflista.shape[0]\n",
    "dflista['archivo_csv']=''\n",
    "for i in range(0, total_f):\n",
    "    '''ruta del archivo'''\n",
    "    nom_arch0 = dflista['nom_archivo'][i]\n",
    "    cond = dflista['formato'][i]\n",
    "    ruta_archivo = '../datos/formato'+str(cond)+'/'+nom_arch0\n",
    "    if (cond == 1):\n",
    "        '''para formato 1'''\n",
    "        dfarchivo = leer1(ruta_archivo)\n",
    "        df0_res = asignar1(dfarchivo)\n",
    "    else:\n",
    "        if (cond == 2):\n",
    "            '''para formato 2'''\n",
    "            df0_res = leer2(ruta_archivo)\n",
    "        else:\n",
    "            '''para formato 3'''\n",
    "            df0_res = leer3(ruta_archivo)\n",
    "            \n",
    "    \n",
    "    '''columna fecha'''                \n",
    "    df0_res['fecha']=df0_res['anio'].astype(str)+'-'+df0_res['mes'].astype(str)+'-'+df0_res['dia'].astype(str)\n",
    "    df0_res['fecha']=pd.to_datetime(df0_res['fecha'])\n",
    "    \n",
    "    '''reordenar las columnas'''\n",
    "    df0_res = df0_res.reindex(['fecha','pp','tmax','tmin','tmed','hmax','hmin','hmed'], axis=1)\n",
    "    \n",
    "    '''grabar el resultado en la direccion especificada'''\n",
    "    ran_fech = '_'+str(df0_res['fecha'].iloc[0].year)+str(df0_res['fecha'].iloc[0].month)+'_'+str(df0_res['fecha'].iloc[-1].year)+str(df0_res['fecha'].iloc[-1].month)\n",
    "    nombre = str(dflista['id'][i])+'_'+dflista['depto'][i]+'_'+dflista['estacion'][i]+ran_fech+'.csv'\n",
    "    ruta_guardar = '../datos/formato_csv/'+nombre\n",
    "    grabar(df0_res, ruta_guardar)\n",
    "    \n",
    "    '''guardar el nombre de los archivos en estaciones_senamhi.csv'''\n",
    "    #dflista['archivo_csv'][i] = nombre\n",
    "    dflista.loc[i,'archivo_csv'] = nombre\n",
    "    \n",
    "grabar(dflista, path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e6dbb",
   "metadata": {},
   "source": [
    "### Completar información de estaciones: Challapata y Curahuara\n",
    "- Para estación de Challapata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b0abbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80926/2626361088.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chall['id'][0]=116\n",
      "/tmp/ipykernel_80926/2626361088.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chall['archivo_csv'][0]=nombre_ch\n"
     ]
    }
   ],
   "source": [
    "'''leer archivo estaciones_senamhi.csv'''\n",
    "ruta_arch = '../datos/estaciones_senamhi.csv'\n",
    "dflista = pd.read_csv(path_file)\n",
    "\n",
    "consul1 = dflista [dflista ['estacion'] == 'challapata'].index\n",
    "ruta_chall0 = '../datos/formato_csv/'+dflista['archivo_csv'].iloc[consul1[0]]\n",
    "ruta_chall1 = '../datos/formato_csv/'+dflista['archivo_csv'].iloc[consul1[1]]\n",
    "\n",
    "'''leer los archivos a concatenar'''\n",
    "df_challapata0 = pd.read_csv(ruta_chall0)\n",
    "df_challapata1 = pd.read_csv(ruta_chall1)\n",
    "\n",
    "\n",
    "'''eliminar las filas del 2011 en df_challapata1'''\n",
    "indice = df_challapata1[(df_challapata1['fecha'] == '2011-12-31')].index\n",
    "df_challapata1.drop(range(0,indice[0]+1), inplace = True, axis = 0)\n",
    "\n",
    "'''concatenar challapata0 y challapata1'''\n",
    "df_challapata = pd.concat([df_challapata0, df_challapata1])\n",
    "df_challapata.reset_index(drop = True, inplace = True)\n",
    "\n",
    "'''guardar'''\n",
    "nombre_ch = '116_oruro_challapata_19424_20182.csv'\n",
    "path_f3 = '../datos/formato_csv/'+nombre_ch\n",
    "df_challapata.to_csv(path_f3, index = False)\n",
    "\n",
    "\n",
    "chall = pd.DataFrame()\n",
    "chall = chall.append(dflista.iloc[consul1[0]])\n",
    "chall.reset_index(drop = True, inplace = True)\n",
    "chall.drop(['codigo','nom_archivo','formato'], inplace = True, axis = 1)\n",
    "chall['id'][0]=116\n",
    "chall['archivo_csv'][0]=nombre_ch\n",
    "\n",
    "dflista = dflista.append(chall)\n",
    "dflista.drop([consul1[0], consul1[1]], inplace = True, axis = 0)\n",
    "dflista.drop(['nom_archivo','formato'], inplace = True, axis = 1)\n",
    "dflista.reset_index(drop = True, inplace = True)\n",
    "dflista['id']=dflista['id'].astype(int)\n",
    "dflista['altitud']=dflista['altitud'].astype(int)\n",
    "\n",
    "\n",
    "path_f3 = '../datos/estaciones_senamhi_generado.csv'\n",
    "dflista.to_csv(path_f3, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b79b6b",
   "metadata": {},
   "source": [
    "- Para estación de Curahuara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a889ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''leer archivo estaciones_senamhi.csv'''\n",
    "ruta_arch = '../datos/estaciones_senamhi.csv'\n",
    "dflista = pd.read_csv(path_file)\n",
    "\n",
    "consul2 = dflista [dflista ['estacion'] == 'curahuara'].index\n",
    "ruta_curah0 = '../datos/formato_csv/'+dflista['archivo_csv'].iloc[consul2[0]]\n",
    "ruta_curah1 = '../datos/formato_csv/'+dflista['archivo_csv'].iloc[consul2[1]]\n",
    "\n",
    "'''leer los archivos a concatenar'''\n",
    "df_curahuara0 = pd.read_csv(ruta_curah0)\n",
    "df_curahuara1 = pd.read_csv(ruta_curah1)\n",
    "\n",
    "\n",
    "'''Crear un DF vacio para el 2012'''\n",
    "col = df_curahuara0.columns\n",
    "df_curahuara2 = pd.DataFrame(columns=col)\n",
    "\n",
    "'''crear una columna con las fechas dentro el rango'''\n",
    "df_curahuara2['fecha'] = pd.date_range(start='2012-01-01',end='2012-12-31')\n",
    "df_curahuara2['fecha'] = pd.to_datetime(df_curahuara2['fecha']).dt.date\n",
    "\n",
    "df_curahuara = pd.concat([df_curahuara0, df_curahuara2, df_curahuara1])\n",
    "df_curahuara.reset_index(drop = True, inplace = True)\n",
    "\n",
    "nombre_cu = '117_oruro_curahuara_19759_20193.csv'\n",
    "path_f4 = '../datos/formato_csv/'+nombre_cu\n",
    "df_curahuara.to_csv(path_f4, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6c44e",
   "metadata": {},
   "source": [
    "- Crear \"estaciones_senamhi_generado.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e7a174",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chall = pd.DataFrame()\n",
    "chall = chall.append(dflista.iloc[consul1[0]])\n",
    "chall.reset_index(drop = True, inplace = True)\n",
    "chall.drop(['codigo','nom_archivo','formato'], inplace = True, axis = 1)\n",
    "chall.loc[0,'id']=116\n",
    "chall.loc[0,'archivo_csv']=nombre_ch\n",
    "\n",
    "consul2 = dflista [dflista ['estacion'] == 'curahuara'].index\n",
    "curah = pd.DataFrame()\n",
    "curah = curah.append(dflista.iloc[consul2[0]])\n",
    "curah.reset_index(drop = True, inplace = True)\n",
    "curah.drop(['codigo','nom_archivo','formato'], inplace = True, axis = 1)\n",
    "curah.loc[0,'id']=117\n",
    "curah.loc[0,'archivo_csv']=nombre_cu\n",
    "\n",
    "\n",
    "dflista = dflista.append(chall)\n",
    "\n",
    "dflista = dflista.append(curah)\n",
    "\n",
    "dflista.drop([consul1[0], consul1[1],consul2[0], consul2[1]], inplace = True, axis = 0)\n",
    "dflista.drop(['nom_archivo','formato'], inplace = True, axis = 1)\n",
    "dflista.reset_index(drop = True, inplace = True)\n",
    "dflista['id']=dflista['id'].astype(int)\n",
    "dflista['altitud']=dflista['altitud'].astype(int)\n",
    "dflista['codigo']=dflista['codigo'].fillna(0)\n",
    "dflista['codigo']=dflista['codigo'].astype(int)\n",
    "\n",
    "path_f3 = '../datos/estaciones_senamhi_generado.csv'\n",
    "dflista.to_csv(path_f3, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489de71a",
   "metadata": {},
   "source": [
    "### Datos entre limites d1 <= datos <= d2, revisar los archivos CSV en busca de strings y convertirlos a NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18433bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Se define Periodo de Análisis: f1=Fecha de Inicio y f2=Fecha de Finalización '''\n",
    "f1=pd.Timestamp(1981, 1, 1)\n",
    "f2=pd.Timestamp(2020, 12, 31)\n",
    "\n",
    "def genera_rango (d1, d2, columnas, frontera ):\n",
    "    vacio = pd.DataFrame(columns = columnas)\n",
    "    vacio['fecha']=pd.date_range(start=d1,end=d2,closed=frontera)\n",
    "    return vacio\n",
    "    \n",
    "def limite (d1, d2, data):\n",
    "    data['fecha'] = pd.to_datetime(data['fecha'])\n",
    "    if (d1 < data['fecha'].iloc[0]):\n",
    "        datainf = genera_rango(d1, data['fecha'].iloc[0], data.columns, 'left')\n",
    "        data = datainf.append(data, ignore_index = True)\n",
    "    if (data['fecha'].iloc[-1] < d2):\n",
    "        datasup = genera_rango(data['fecha'].iloc[-1], d2, data.columns, 'right')\n",
    "        data = data.append(datasup, ignore_index = True)\n",
    "    if (d1 > data['fecha'].iloc[0]):\n",
    "        indiceinf = data[(data['fecha'] == d1)].index\n",
    "        data.drop(range(0,indiceinf[0]), inplace = True, axis = 0)\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "    if (data['fecha'].iloc[-1] > d2):\n",
    "        indicesup = data[(data['fecha'] == d2)].index\n",
    "        data.drop(range(indicesup[-1]+1,data.shape[0]), inplace = True, axis = 0)\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "'''metodo para cambiar las cadenas en nan y los numeros en float'''\n",
    "def cambiar(data):\n",
    "    tam = data.shape[0]\n",
    "    for x in range (0, tam):\n",
    "        for y in range (1, 8):\n",
    "            try:\n",
    "                data.iloc[x,y] = float(data.iloc[x,y])\n",
    "            except ValueError:\n",
    "                data.iloc[x,y] = np.nan\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39ab9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_f3 = '../datos/estaciones_senamhi_generado.csv'\n",
    "dflista = pd.read_csv(path_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2e0d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflista['archivo_csv_corregido'] = ''\n",
    "\n",
    "for p in dflista['archivo_csv']:\n",
    "    pin = '../datos/formato_csv/'+p\n",
    "    file = pd.read_csv(pin)\n",
    "    rfile = limite(f1,f2,file) \n",
    "    cfile = cambiar(rfile)\n",
    "    \n",
    "    cad=p.split('_')\n",
    "    pmod='obs_'+cad[0]+'_'+cad[2]+'.csv'\n",
    "    pout = '../datos/formato_csv_corregido/'+pmod\n",
    "    cfile.to_csv(pout, index = False)\n",
    "    \n",
    "    indice = dflista[dflista['archivo_csv'] == p].index[0]\n",
    "    dflista.at[indice, 'archivo_csv_corregido'] = pmod\n",
    "\n",
    "dflista = dflista.sort_values('id', ascending=True)\n",
    "dflista.reset_index(drop=True, inplace=True)\n",
    "dflista.to_csv(path_f3, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf361ca",
   "metadata": {},
   "source": [
    "## Para generar dataframe para cada variable meteorológica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "509657de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creardf(data, col):\n",
    "    dat = pd.DataFrame()\n",
    "    dat[col] = data[col]\n",
    "    return dat\n",
    "\n",
    "def guardar(data, nom, path='../datos/por_variables/'):\n",
    "    pth = path + nom\n",
    "    data.to_csv(pth, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd81b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_f3 = '../datos/estaciones_senamhi_generado.csv'\n",
    "dflista = pd.read_csv(path_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49fda6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('../datos/formato_csv_corregido/obs_100_aeropuerto.csv')\n",
    "\n",
    "dfpp = creardf(temp,['fecha'])\n",
    "dftmx = creardf(temp,['fecha'])\n",
    "dftmn = creardf(temp,['fecha'])\n",
    "dftmd = creardf(temp,['fecha'])\n",
    "dfhmx = creardf(temp,['fecha'])\n",
    "dfhmn = creardf(temp,['fecha'])\n",
    "dfhmd = creardf(temp,['fecha'])\n",
    "nom_col = ['fecha']\n",
    "\n",
    "for p in dflista['archivo_csv_corregido']:\n",
    "    pin = '../datos/formato_csv_corregido/' + p\n",
    "    file = pd.read_csv(pin)\n",
    "    dfpp = pd.concat([dfpp, file['pp']], axis=1)\n",
    "    dftmx = pd.concat([dftmx, file['tmax']], axis=1)\n",
    "    dftmn = pd.concat([dftmn, file['tmin']], axis=1)\n",
    "    dftmd = pd.concat([dftmd, file['tmed']], axis=1)\n",
    "    dfhmx = pd.concat([dfhmx, file['hmax']], axis=1)\n",
    "    dfhmn = pd.concat([dfhmn, file['hmin']], axis=1)\n",
    "    dfhmd = pd.concat([dfhmd, file['hmed']], axis=1)\n",
    "    \n",
    "    cad = p.split('_')\n",
    "    nom_col.append(str(cad[1]))\n",
    "    \n",
    "dfpp.columns = nom_col\n",
    "dftmx.columns = nom_col\n",
    "dftmn.columns = nom_col\n",
    "dftmd.columns = nom_col\n",
    "dfhmx.columns = nom_col\n",
    "dfhmn.columns = nom_col\n",
    "dfhmd.columns = nom_col\n",
    "\n",
    "guardar(dfpp, 'obs_diario_pp.csv')\n",
    "guardar(dftmx, 'obs_diario_tmax.csv')\n",
    "guardar(dftmn, 'obs_diario_tmin.csv')\n",
    "guardar(dftmd, 'obs_diario_tmed.csv')\n",
    "guardar(dfhmx, 'obs_diario_hmax.csv')\n",
    "guardar(dfhmn, 'obs_diario_hmin.csv')\n",
    "guardar(dfhmd, 'obs_diario_hmed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "095375ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=2408, microseconds=903822)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = datetime.datetime.now()\n",
    "t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533925b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
